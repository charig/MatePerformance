<<LanguagesPerformance, echo=FALSE, message=FALSE>>=
knitr::opts_chunk$set(fig.width=10, fig.height=5, results="asis")

steady <- getFilteredData("../../Data/areWeFast.data", c("Value", "Benchmark", "VM", "Suite", "Iteration"), vmNamesMap(), iterationsAndInliningFilename, iterationsAndInliningCols, numberOfIterationsPerBenchmarks)

normalizedSteady <- ddply(steady, ~ Benchmark, transform,
                RuntimeRatio = Value / mean(Value[VM == "Java"]))
normalizedSteady <- droplevels(subset(normalizedSteady, VM != "Java"))  

summarizedPerBench <- ddply(normalizedSteady, ~ VM + Benchmark, summarise,
               RuntimeFactor = geometric.mean(RuntimeRatio),
               sd            = sd(RuntimeRatio),
               median        = median(RuntimeRatio))

summarizedPerBenchAndVM <- ddply(summarizedPerBench, ~ VM, transform,
    VMMean = geometric.mean(RuntimeFactor),
    min = min(RuntimeFactor),
    max = max(RuntimeFactor))

summarizedOverall <- summarizeOverall(summarizedPerBenchAndVM)

vm_colors <- brewer.pal(12, "Paired")  # to replace scale_fill_brewer(type = "qual", palette = "Paired")
names(vm_colors) <- vmNamesMap()

@
\def\LanguagesPerfComparisonPlot{%
<<languages-perf-overview, echo=FALSE, message=FALSE>>=
print(overview_box_plot(summarizedPerBenchAndVM))
@
}%
\def\LanguagesTableSummary{%
<<languages-summary-table>>=
print(xtable(arrange(summarizedPerBenchAndVM, Benchmark)))
@
}
\def\LanguagesTableOverall{%
<<languages-overall-table>>=
print(xtable(summarizedOverall))
@
}